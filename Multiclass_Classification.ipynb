{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9b8490b-77ed-4a52-9fbb-bc4a9f2923e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7e0c15-3307-4c2d-bfef-b4e005d338eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rps-test-set.zip', <http.client.HTTPMessage at 0x25f06dd6fd0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url=\"https://storage.googleapis.com/learning-datasets/rps.zip\"\n",
    "urllib.request.urlretrieve(url,\"rps.zip\")\n",
    "\n",
    "url2=\"https://storage.googleapis.com/learning-datasets/rps-test-set.zip\"\n",
    "urllib.request.urlretrieve(url2,'rps-test-set.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7119efa8-5b52-4dcd-8621-cb67401f747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('rps.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('rps')\n",
    "\n",
    "with zipfile.ZipFile('rps-test-set.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('rps-test-set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c884fba-3e50-4a03-aee3-47696e7325ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir=\"rps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "348d3e2f-4187-4156-bd6c-b4ec07ef8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dir='rps-test-set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98450578-5bec-45cd-a8aa-2dcb18a6d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen=ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "09eb505e-dcb6-4618-82fa-d505ea369a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 372 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3699a57f-0197-4eea-ac57-bab7c6311b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "training_datagen=ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3dc7cc96-78a8-4bdd-8081-573605a4a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "training_generator=training_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(150,150),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fce6a32d-8bbe-45fa-ba1b-20edba759b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c2f5646-a3db-47ab-aa13-9186a9a62605",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8bf4f204-b92e-422d-b9f7-dee992674f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 960ms/step - accuracy: 0.9873 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 3.1757e-07\n",
      "Epoch 2/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 958ms/step - accuracy: 1.0000 - loss: 4.9699e-07 - val_accuracy: 1.0000 - val_loss: 4.1018e-08\n",
      "Epoch 3/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 941ms/step - accuracy: 1.0000 - loss: 2.1268e-07 - val_accuracy: 1.0000 - val_loss: 1.5382e-08\n",
      "Epoch 4/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 961ms/step - accuracy: 1.0000 - loss: 1.3690e-07 - val_accuracy: 1.0000 - val_loss: 3.5250e-09\n",
      "Epoch 5/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 959ms/step - accuracy: 1.0000 - loss: 8.5339e-08 - val_accuracy: 1.0000 - val_loss: 9.6137e-10\n",
      "Epoch 6/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 961ms/step - accuracy: 1.0000 - loss: 6.9018e-08 - val_accuracy: 1.0000 - val_loss: 3.2046e-10\n",
      "Epoch 7/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 958ms/step - accuracy: 1.0000 - loss: 6.9160e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 957ms/step - accuracy: 1.0000 - loss: 5.1090e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 959ms/step - accuracy: 1.0000 - loss: 7.4978e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 957ms/step - accuracy: 1.0000 - loss: 4.1723e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 956ms/step - accuracy: 1.0000 - loss: 4.5224e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 959ms/step - accuracy: 1.0000 - loss: 2.8383e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 962ms/step - accuracy: 1.0000 - loss: 2.7863e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 960ms/step - accuracy: 1.0000 - loss: 3.0701e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 974ms/step - accuracy: 1.0000 - loss: 2.5403e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 963ms/step - accuracy: 1.0000 - loss: 2.2328e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 947ms/step - accuracy: 1.0000 - loss: 2.5403e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 960ms/step - accuracy: 1.0000 - loss: 1.6793e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 958ms/step - accuracy: 1.0000 - loss: 1.7030e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 963ms/step - accuracy: 1.0000 - loss: 2.4693e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 981ms/step - accuracy: 1.0000 - loss: 1.7881e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 963ms/step - accuracy: 1.0000 - loss: 1.5895e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 959ms/step - accuracy: 1.0000 - loss: 1.5516e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 960ms/step - accuracy: 1.0000 - loss: 2.1997e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/25\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 959ms/step - accuracy: 1.0000 - loss: 1.2820e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    training_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d26cc201-ffb5-47dc-a742-9594250e24af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "prediction:  rock\n",
      "confidence:  1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "fn='Mtest.jpg'\n",
    "path = fn\n",
    "img = image.load_img(path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "x=x/255.0\n",
    "prediction=model.predict(x)\n",
    "classes=['paper','rock','scissor']\n",
    "result=classes[np.argmax(prediction)]\n",
    "\n",
    "print(\"prediction: \",result)\n",
    "print(\"confidence: \",np.max(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b0843847-7b43-4fb2-a873-67f31ff6e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rps_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bfdeeaab-b128-4c24-8c98-7795896b2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model('rps_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e23bc9-4f37-46af-86e1-169d6220b715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CUDA)",
   "language": "python",
   "name": "cuda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
